{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipped Images with ratio\n",
    "def random_flipped_img(images, labels, flip_ratio):\n",
    "    num_flips = int(len(images) * flip_ratio)\n",
    "    random_choice = np.random.choice(len(images), num_flips, replace=False)\n",
    "    new_images = []\n",
    "    new_labels = []\n",
    "    new_classes = []\n",
    "    for i, (img,label) in enumerate(zip(images,labels)):\n",
    "        if i in random_choice:\n",
    "            flipped_img = np.flip(img, axis=0)\n",
    "            new_images.append(flipped_img)\n",
    "            new_labels.append(1) # 1 for flip\n",
    "            new_classes.append(label)\n",
    "        else:\n",
    "            new_images.append(img)\n",
    "            new_labels.append(0) # 0 for not flip\n",
    "            new_classes.append(label)\n",
    "    return new_images, new_labels, new_classes\n",
    "\n",
    "# Load dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "# Normalize the RGB values to be between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "# Ratio of train and test (8:2)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Total images of train and test set after apply ratio\n",
    "total_train_num = int(len(train_images))\n",
    "total_test_num = int(len(test_images))\n",
    "\n",
    "print(\"Total images of train set:\",total_train_num)\n",
    "print(\"Total images of test set: \", total_test_num)\n",
    "\n",
    "# Select random images from train set\n",
    "random_indices_train = np.random.choice(len(train_images), total_train_num, replace=False)\n",
    "selected_train_images = train_images[random_indices_train]\n",
    "selected_train_labels = train_labels[random_indices_train]\n",
    "\n",
    "# Select random images from test set\n",
    "random_indices_test = np.random.choice(len(test_images), total_test_num, replace=False)\n",
    "selected_test_images = test_images[random_indices_test]\n",
    "selected_test_labels = test_labels[random_indices_test]\n",
    "\n",
    "# Fiptting ratio\n",
    "flip_ratio = 0.5\n",
    "# train - images and labels after flippting randomly\n",
    "flipped_train_images, flipped_train_labels, flipped_train_classes = random_flipped_img(selected_train_images, selected_train_labels, flip_ratio)\n",
    "\n",
    "# test - images and labels after flippting randomly\n",
    "flipped_test_images, flipped_test_labels, flipped_test_classes = random_flipped_img(selected_test_images, selected_test_labels, flip_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images\n",
    "def resize_images(images):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        resized_image = resize(image, (28, 28))\n",
    "        if len(resized_image.shape) == 2:\n",
    "            resized_image = np.expand_dims(resized_image, axis=-1)\n",
    "        resized_image = np.mean(resized_image, axis=2) \n",
    "        resized_images.append(resized_image)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "# Convert to numpy arrays and normalize\n",
    "train_images = np.array(flipped_train_images) / 255.0\n",
    "train_labels = np.array(flipped_train_labels)\n",
    "train_classes = np.array(flipped_train_classes)\n",
    "\n",
    "test_images = np.array(flipped_test_images) / 255.0\n",
    "test_labels = np.array(flipped_test_labels)\n",
    "test_classes = np.array(flipped_test_classes)\n",
    "\n",
    "train_images_resized = resize_images(train_images)\n",
    "test_images_resized = resize_images(test_images)\n",
    "input_shape = train_images_resized[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Values\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 0.0005,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "\n",
    "# Define CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    #tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    #tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_images_resized,\n",
    "    train_labels,\n",
    "    epochs=3,\n",
    "    batch_size=64, # 16 32 64 128 256 vv \n",
    "    validation_data=(test_images_resized, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#  CNN prediction by passing the whole test set  #\n",
    "##################################################\n",
    "\n",
    "# prediction = model.predict(test_images_resized)\n",
    "# predicted_labels_CNN = np.argmax(prediction, axis=1) \n",
    "# accuracy1 = accuracy_score(test_labels, predicted_labels_CNN)\n",
    "\n",
    "# print(predicted_labels_CNN)\n",
    "# print(test_labels)\n",
    "# print(\"Accuracy:\", accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#  CNN prediction by passing per image test set  #\n",
    "##################################################\n",
    "predicted_labels_CNN = []\n",
    "\n",
    "for i in range(len(test_images_resized)):\n",
    "    # Make prediction on a single image\n",
    "    prediction = model.predict(np.expand_dims(test_images_resized[i], axis=0))\n",
    "    # Add label after prediction into array\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    predicted_labels_CNN.append(predicted_label)\n",
    "\n",
    "print(\"Predicted labels of images:\", predicted_labels_CNN)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels_CNN)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predicted_labels_RF = []\n",
    "\n",
    "# Define Random Forest model\n",
    "# Increase accuracy => increase number of trees\n",
    "RF = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "\n",
    "# Flatten the images for compatibility with non-CNN models\n",
    "train_images_flattened = tf.reshape(train_images_resized, (train_images_resized.shape[0], -1))\n",
    "test_images_flattened = tf.reshape(test_images_resized, (test_images_resized.shape[0], -1))\n",
    "# Train the Random Forest Classifier\n",
    "RF.fit(train_images_flattened, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################################################\n",
    "# # Random Forest prediction by passing the whole test set   #\n",
    "# ############################################################\n",
    "\n",
    "\n",
    "# # Random Forest Prediction -> Use as Replace Solution -> Will be update on future later\n",
    "# predicted_labels_RF = RF.predict(test_images_flattened)\n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(test_labels, predicted_labels_RF)\n",
    "# print(test_labels)\n",
    "# print(predicted_labels_RF)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################################################\n",
    "# # Random Forest prediction by passing per image in test set  #\n",
    "# ##############################################################\n",
    "\n",
    "for i in range(len(test_images_flattened)):\n",
    "    # Make prediction on a single image\n",
    "    prediction = RF.predict(np.expand_dims(test_images_flattened[i], axis=0))\n",
    "    # Add label after prediction into array\n",
    "    predicted_label = prediction[0]\n",
    "    predicted_labels_RF.append(predicted_label)\n",
    "\n",
    "print(\"Predicted labels of images:\", predicted_labels_RF)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(test_labels, predicted_labels_RF)\n",
    "print(\"Accuracy:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "classes = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "# Mapping predicted labels to class names\n",
    "predicted_class_names = [classes[label] for label in flipped_test_classes]\n",
    "\n",
    "# Count occurrences of each class in predicted class names\n",
    "class_counts = Counter(predicted_class_names)\n",
    "\n",
    "# Display class counts\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count} occurrences\")\n",
    "    \n",
    "predicted_sum = []\n",
    "for i in range (len(predicted_labels_CNN)):\n",
    "    if predicted_labels_CNN[i] == predicted_labels_RF[i]:\n",
    "        predicted_sum.append(predicted_labels_CNN[i])\n",
    "    else:\n",
    "        # Check if the true label is diffrent with the prediction of CNN or Random Forest\n",
    "        if flipped_test_labels[i] != predicted_labels_CNN[i]:\n",
    "            predicted_sum.append(predicted_labels_CNN[i])\n",
    "        if flipped_test_labels[i] != predicted_labels_RF[i]:\n",
    "            predicted_sum.append(predicted_labels_RF[i])\n",
    "\n",
    "# Initialize a dictionary to store misclassification counts for each class\n",
    "class_misclassified_counts = {class_name: {'count': 0, 'positions': []} for class_name in classes.values()}\n",
    "\n",
    "# Iterate through true labels and predicted labels simultaneously\n",
    "for i, (true_label, predicted_label, class_name) in enumerate(zip(flipped_test_labels, predicted_sum, predicted_class_names)):\n",
    "    if true_label != predicted_label:\n",
    "        class_misclassified_counts[class_name]['count'] += 1\n",
    "        class_misclassified_counts[class_name]['positions'].append(i)\n",
    "\n",
    "print(\"\\n\")\n",
    "# Display misclassification counts for each class\n",
    "for class_name, info in class_misclassified_counts.items():\n",
    "    print(f\"Class: {class_name}, Misclassified Count: {info['count']}, Positions: {info['positions']}\")\n",
    "\n",
    "\n",
    "# Sort the misclassification counts dictionary by count in descending order\n",
    "sorted_misclassified_counts = sorted(class_misclassified_counts.items(), key=lambda x: x[1]['count'], reverse=True)\n",
    "\n",
    "# Display the top 3 classes with the highest misclassification counts\n",
    "print(\"\\n\\nTop 3 classes with the highest misclassification counts:\")\n",
    "for i, (class_name, info) in enumerate(sorted_misclassified_counts[:3]):\n",
    "    print(f\"{i+1}. Class: {class_name}, Misclassified Count: {info['count']}, Positions: {info['positions']}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "selected_positions = []\n",
    "\n",
    "num_images_per_class = 10\n",
    "\n",
    "# Iterate through the top 3 misclassified classes\n",
    "for class_name, info in sorted_misclassified_counts[:3]:\n",
    "    # Shuffle the positions for each class\n",
    "    random.shuffle(info['positions'])\n",
    "    # Select up to num_images_per_class positions from each class\n",
    "    selected_positions.extend(info['positions'][:num_images_per_class])\n",
    "\n",
    "# Plot 10 random images from each of the top 3 misclassified classes\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, (class_name, info) in enumerate(sorted_misclassified_counts[:3]):\n",
    "    # Shuffle the positions for each class\n",
    "    random.shuffle(info['positions'])\n",
    "    # Select up to num_images_per_class positions from each class\n",
    "    class_selected_positions = info['positions'][:num_images_per_class]\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    for j, position in enumerate(class_selected_positions):\n",
    "        plt.subplot(3, num_images_per_class, i * num_images_per_class + j + 1)\n",
    "        plt.imshow(flipped_test_images[position], cmap='gray')\n",
    "        plt.title(f\"{class_name}\\nTrue Label: {flipped_test_labels[position]}\\nPredicted Label: {predicted_sum[position]}\\nPosition: {position}\", fontsize=10)\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
